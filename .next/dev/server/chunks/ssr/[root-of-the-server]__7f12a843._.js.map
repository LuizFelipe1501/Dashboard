{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 10, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/luizf/Documents/GitHub/Hallucinationchecker/dashboard/app/components/CameraView.tsx"],"sourcesContent":["\"use client\";\r\n\r\nimport { useEffect, useRef } from \"react\";\r\n\r\ntype Point = { x: number; y: number };\r\n\r\nfunction lerp(a: number, b: number, t: number) {\r\n  return a + (b - a) * t;\r\n}\r\n\r\nfunction lerpPolygon(from: Point[], to: Point[], t: number): Point[] {\r\n  if (!from || from.length !== to.length) return to;\r\n  return from.map((p, i) => ({\r\n    x: lerp(p.x, to[i].x, t),\r\n    y: lerp(p.y, to[i].y, t)\r\n  }));\r\n}\r\n\r\nexport default function CameraView() {\r\n  const videoRef = useRef<HTMLVideoElement>(null);\r\n  const overlayRef = useRef<HTMLCanvasElement>(null);\r\n  const captureRef = useRef<HTMLCanvasElement>(null);\r\n\r\n  const busy = useRef(false);\r\n\r\n  // üî• estados para suaviza√ß√£o\r\n  const prevPolygons = useRef<Point[][]>([]);\r\n  const targetPolygons = useRef<Point[][]>([]);\r\n  const alpha = useRef(1);\r\n\r\n  useEffect(() => {\r\n    let detectionTimer: any;\r\n    let rafId: number;\r\n\r\n    async function startCamera() {\r\n      const stream = await navigator.mediaDevices.getUserMedia({\r\n        video: { width: 640, height: 480 }\r\n      });\r\n\r\n      const video = videoRef.current!;\r\n      video.srcObject = stream;\r\n\r\n      video.onloadedmetadata = () => {\r\n        video.play();\r\n        setupCanvases();\r\n        animate();\r\n        startDetectionLoop();\r\n      };\r\n    }\r\n\r\n    function setupCanvases() {\r\n      const video = videoRef.current!;\r\n      overlayRef.current!.width = video.videoWidth;\r\n      overlayRef.current!.height = video.videoHeight;\r\n      captureRef.current!.width = video.videoWidth;\r\n      captureRef.current!.height = video.videoHeight;\r\n    }\r\n\r\n    function animate() {\r\n      const canvas = overlayRef.current!;\r\n      const ctx = canvas.getContext(\"2d\")!;\r\n      ctx.clearRect(0, 0, canvas.width, canvas.height);\r\n\r\n      ctx.strokeStyle = \"#00ff00\";\r\n      ctx.lineWidth = 3;\r\n\r\n      const smoothed = targetPolygons.current.map((poly, i) =>\r\n        lerpPolygon(\r\n          prevPolygons.current[i] ?? poly,\r\n          poly,\r\n          alpha.current\r\n        )\r\n      );\r\n\r\n      smoothed.forEach(polygon => {\r\n        ctx.beginPath();\r\n        polygon.forEach((p, i) => {\r\n          const x = p.x * canvas.width;\r\n          const y = p.y * canvas.height;\r\n          i === 0 ? ctx.moveTo(x, y) : ctx.lineTo(x, y);\r\n        });\r\n        ctx.closePath();\r\n        ctx.stroke();\r\n      });\r\n\r\n      alpha.current = Math.min(alpha.current + 0.08, 1);\r\n      rafId = requestAnimationFrame(animate);\r\n    }\r\n\r\n    async function detectOnce() {\r\n      if (busy.current) return;\r\n      busy.current = true;\r\n\r\n      const video = videoRef.current!;\r\n      const canvas = captureRef.current!;\r\n      const ctx = canvas.getContext(\"2d\")!;\r\n\r\n      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\r\n\r\n      canvas.toBlob(async blob => {\r\n        if (!blob) {\r\n          busy.current = false;\r\n          return;\r\n        }\r\n\r\n        try {\r\n          const formData = new FormData();\r\n          formData.append(\"file\", blob, \"frame.jpg\");\r\n\r\n          const res = await fetch(\r\n            \"https://hallucination.calmwave-93bbec10.brazilsouth.azurecontainerapps.io/detect\",\r\n            {\r\n              method: \"POST\",\r\n              body: formData\r\n            }\r\n          );\r\n\r\n          const data = await res.json();\r\n          const polygons = data.polygons ?? [];\r\n\r\n          // üî• atualiza alvos para interpola√ß√£o\r\n          prevPolygons.current = targetPolygons.current.length\r\n            ? targetPolygons.current\r\n            : polygons;\r\n\r\n          targetPolygons.current = polygons;\r\n          alpha.current = 0;\r\n\r\n        } catch (err) {\r\n          console.error(err);\r\n        } finally {\r\n          busy.current = false;\r\n        }\r\n      }, \"image/jpeg\", 0.6);\r\n    }\r\n\r\n    function startDetectionLoop() {\r\n      detectionTimer = setInterval(detectOnce, 1000); // 1 FPS\r\n    }\r\n\r\n    startCamera();\r\n\r\n    return () => {\r\n      clearInterval(detectionTimer);\r\n      cancelAnimationFrame(rafId);\r\n    };\r\n  }, []);\r\n\r\n  return (\r\n    <div className=\"relative w-[640px] h-[480px] bg-black\">\r\n      <video\r\n        ref={videoRef}\r\n        className=\"absolute top-0 left-0 w-full h-full object-cover rounded-xl\"\r\n        muted\r\n        playsInline\r\n        autoPlay\r\n      />\r\n\r\n      <canvas\r\n        ref={overlayRef}\r\n        className=\"absolute top-0 left-0 w-full h-full pointer-events-none\"\r\n      />\r\n\r\n      <canvas ref={captureRef} className=\"hidden\" />\r\n    </div>\r\n  );\r\n}\r\n"],"names":[],"mappings":";;;;;AAEA;AAFA;;;AAMA,SAAS,KAAK,CAAS,EAAE,CAAS,EAAE,CAAS;IAC3C,OAAO,IAAI,CAAC,IAAI,CAAC,IAAI;AACvB;AAEA,SAAS,YAAY,IAAa,EAAE,EAAW,EAAE,CAAS;IACxD,IAAI,CAAC,QAAQ,KAAK,MAAM,KAAK,GAAG,MAAM,EAAE,OAAO;IAC/C,OAAO,KAAK,GAAG,CAAC,CAAC,GAAG,IAAM,CAAC;YACzB,GAAG,KAAK,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE;YACtB,GAAG,KAAK,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE;QACxB,CAAC;AACH;AAEe,SAAS;IACtB,MAAM,WAAW,IAAA,4NAAM,EAAmB;IAC1C,MAAM,aAAa,IAAA,4NAAM,EAAoB;IAC7C,MAAM,aAAa,IAAA,4NAAM,EAAoB;IAE7C,MAAM,OAAO,IAAA,4NAAM,EAAC;IAEpB,6BAA6B;IAC7B,MAAM,eAAe,IAAA,4NAAM,EAAY,EAAE;IACzC,MAAM,iBAAiB,IAAA,4NAAM,EAAY,EAAE;IAC3C,MAAM,QAAQ,IAAA,4NAAM,EAAC;IAErB,IAAA,+NAAS,EAAC;QACR,IAAI;QACJ,IAAI;QAEJ,eAAe;YACb,MAAM,SAAS,MAAM,UAAU,YAAY,CAAC,YAAY,CAAC;gBACvD,OAAO;oBAAE,OAAO;oBAAK,QAAQ;gBAAI;YACnC;YAEA,MAAM,QAAQ,SAAS,OAAO;YAC9B,MAAM,SAAS,GAAG;YAElB,MAAM,gBAAgB,GAAG;gBACvB,MAAM,IAAI;gBACV;gBACA;gBACA;YACF;QACF;QAEA,SAAS;YACP,MAAM,QAAQ,SAAS,OAAO;YAC9B,WAAW,OAAO,CAAE,KAAK,GAAG,MAAM,UAAU;YAC5C,WAAW,OAAO,CAAE,MAAM,GAAG,MAAM,WAAW;YAC9C,WAAW,OAAO,CAAE,KAAK,GAAG,MAAM,UAAU;YAC5C,WAAW,OAAO,CAAE,MAAM,GAAG,MAAM,WAAW;QAChD;QAEA,SAAS;YACP,MAAM,SAAS,WAAW,OAAO;YACjC,MAAM,MAAM,OAAO,UAAU,CAAC;YAC9B,IAAI,SAAS,CAAC,GAAG,GAAG,OAAO,KAAK,EAAE,OAAO,MAAM;YAE/C,IAAI,WAAW,GAAG;YAClB,IAAI,SAAS,GAAG;YAEhB,MAAM,WAAW,eAAe,OAAO,CAAC,GAAG,CAAC,CAAC,MAAM,IACjD,YACE,aAAa,OAAO,CAAC,EAAE,IAAI,MAC3B,MACA,MAAM,OAAO;YAIjB,SAAS,OAAO,CAAC,CAAA;gBACf,IAAI,SAAS;gBACb,QAAQ,OAAO,CAAC,CAAC,GAAG;oBAClB,MAAM,IAAI,EAAE,CAAC,GAAG,OAAO,KAAK;oBAC5B,MAAM,IAAI,EAAE,CAAC,GAAG,OAAO,MAAM;oBAC7B,MAAM,IAAI,IAAI,MAAM,CAAC,GAAG,KAAK,IAAI,MAAM,CAAC,GAAG;gBAC7C;gBACA,IAAI,SAAS;gBACb,IAAI,MAAM;YACZ;YAEA,MAAM,OAAO,GAAG,KAAK,GAAG,CAAC,MAAM,OAAO,GAAG,MAAM;YAC/C,QAAQ,sBAAsB;QAChC;QAEA,eAAe;YACb,IAAI,KAAK,OAAO,EAAE;YAClB,KAAK,OAAO,GAAG;YAEf,MAAM,QAAQ,SAAS,OAAO;YAC9B,MAAM,SAAS,WAAW,OAAO;YACjC,MAAM,MAAM,OAAO,UAAU,CAAC;YAE9B,IAAI,SAAS,CAAC,OAAO,GAAG,GAAG,OAAO,KAAK,EAAE,OAAO,MAAM;YAEtD,OAAO,MAAM,CAAC,OAAM;gBAClB,IAAI,CAAC,MAAM;oBACT,KAAK,OAAO,GAAG;oBACf;gBACF;gBAEA,IAAI;oBACF,MAAM,WAAW,IAAI;oBACrB,SAAS,MAAM,CAAC,QAAQ,MAAM;oBAE9B,MAAM,MAAM,MAAM,MAChB,oFACA;wBACE,QAAQ;wBACR,MAAM;oBACR;oBAGF,MAAM,OAAO,MAAM,IAAI,IAAI;oBAC3B,MAAM,WAAW,KAAK,QAAQ,IAAI,EAAE;oBAEpC,sCAAsC;oBACtC,aAAa,OAAO,GAAG,eAAe,OAAO,CAAC,MAAM,GAChD,eAAe,OAAO,GACtB;oBAEJ,eAAe,OAAO,GAAG;oBACzB,MAAM,OAAO,GAAG;gBAElB,EAAE,OAAO,KAAK;oBACZ,QAAQ,KAAK,CAAC;gBAChB,SAAU;oBACR,KAAK,OAAO,GAAG;gBACjB;YACF,GAAG,cAAc;QACnB;QAEA,SAAS;YACP,iBAAiB,YAAY,YAAY,OAAO,QAAQ;QAC1D;QAEA;QAEA,OAAO;YACL,cAAc;YACd,qBAAqB;QACvB;IACF,GAAG,EAAE;IAEL,qBACE,2PAAC;QAAI,WAAU;;0BACb,2PAAC;gBACC,KAAK;gBACL,WAAU;gBACV,KAAK;gBACL,WAAW;gBACX,QAAQ;;;;;;0BAGV,2PAAC;gBACC,KAAK;gBACL,WAAU;;;;;;0BAGZ,2PAAC;gBAAO,KAAK;gBAAY,WAAU;;;;;;;;;;;;AAGzC"}},
    {"offset": {"line": 166, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/luizf/Documents/GitHub/Hallucinationchecker/dashboard/app/components/HudPanel.tsx"],"sourcesContent":["\"use client\";\r\n\r\nimport { ReactNode } from \"react\";\r\n\r\nexport default function HudPanel({ children }: { children: ReactNode }) {\r\n  return (\r\n    <div className=\"relative hud-panel\">\r\n      {/* cantos */}\r\n      <span className=\"hud-corner top-left\" />\r\n      <span className=\"hud-corner top-right\" />\r\n      <span className=\"hud-corner bottom-left\" />\r\n      <span className=\"hud-corner bottom-right\" />\r\n\r\n      {children}\r\n    </div>\r\n  );\r\n}\r\n"],"names":[],"mappings":";;;;;AAAA;;AAIe,SAAS,SAAS,EAAE,QAAQ,EAA2B;IACpE,qBACE,2PAAC;QAAI,WAAU;;0BAEb,2PAAC;gBAAK,WAAU;;;;;;0BAChB,2PAAC;gBAAK,WAAU;;;;;;0BAChB,2PAAC;gBAAK,WAAU;;;;;;0BAChB,2PAAC;gBAAK,WAAU;;;;;;YAEf;;;;;;;AAGP"}},
    {"offset": {"line": 217, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/luizf/Documents/GitHub/Hallucinationchecker/dashboard/app/components/PeopleCounter.tsx"],"sourcesContent":["\"use client\";\r\nimport { useEffect, useState } from \"react\";\r\nimport HudPanel from \"./HudPanel\";\r\n\r\ntype Props = {\r\n  demo?: number | null;\r\n};\r\n\r\nexport default function PeopleCounter({ demo = null }: Props) {\r\n  const [count, setCount] = useState<number>(0);\r\n\r\n  useEffect(() => {\r\n    if (demo !== null) {\r\n      setCount(demo);\r\n      return;\r\n    }\r\n\r\n    let interval: NodeJS.Timeout;\r\n\r\n    const fetchPeople = async () => {\r\n      try {\r\n        const res = await fetch(\r\n          \"https://hallucination.calmwave-93bbec10.brazilsouth.azurecontainerapps.io/status\"\r\n        );\r\n        const data = await res.json();\r\n        setCount(data.people_detected ?? 0);\r\n      } catch {\r\n        setCount(prev => (prev >= 3 ? 1 : prev + 1));\r\n      }\r\n    };\r\n\r\n    fetchPeople();\r\n    interval = setInterval(fetchPeople, 4000);\r\n\r\n    return () => clearInterval(interval);\r\n  }, [demo]);\r\n\r\n  return (\r\n    <HudPanel>\r\n      <h2 className=\"text-xs text-green-400 uppercase tracking-widest\">\r\n        People Detected\r\n      </h2>\r\n\r\n      <p className=\"mt-4 text-5xl font-bold text-green-400\">\r\n        {count}\r\n      </p>\r\n\r\n      <p className=\"mt-2 text-xs text-zinc-500\">\r\n        Camera-based detection\r\n      </p>\r\n    </HudPanel>\r\n  );\r\n}\r\n"],"names":[],"mappings":";;;;;AACA;AACA;AAFA;;;;AAQe,SAAS,cAAc,EAAE,OAAO,IAAI,EAAS;IAC1D,MAAM,CAAC,OAAO,SAAS,GAAG,IAAA,8NAAQ,EAAS;IAE3C,IAAA,+NAAS,EAAC;QACR,IAAI,SAAS,MAAM;YACjB,SAAS;YACT;QACF;QAEA,IAAI;QAEJ,MAAM,cAAc;YAClB,IAAI;gBACF,MAAM,MAAM,MAAM,MAChB;gBAEF,MAAM,OAAO,MAAM,IAAI,IAAI;gBAC3B,SAAS,KAAK,eAAe,IAAI;YACnC,EAAE,OAAM;gBACN,SAAS,CAAA,OAAS,QAAQ,IAAI,IAAI,OAAO;YAC3C;QACF;QAEA;QACA,WAAW,YAAY,aAAa;QAEpC,OAAO,IAAM,cAAc;IAC7B,GAAG;QAAC;KAAK;IAET,qBACE,2PAAC,sJAAQ;;0BACP,2PAAC;gBAAG,WAAU;0BAAmD;;;;;;0BAIjE,2PAAC;gBAAE,WAAU;0BACV;;;;;;0BAGH,2PAAC;gBAAE,WAAU;0BAA6B;;;;;;;;;;;;AAKhD"}},
    {"offset": {"line": 288, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/luizf/Documents/GitHub/Hallucinationchecker/dashboard/app/components/SceneStatus.tsx"],"sourcesContent":["\"use client\";\r\n\r\ntype Props = {\r\n  sceneState: string;\r\n};\r\n\r\nfunction getStatusConfig(scene: string) {\r\n  switch (scene) {\r\n    case \"EMPTY_ENVIRONMENT\":\r\n      return {\r\n        label: \"No people detected\",\r\n        color: \"text-green-400\",\r\n        border: \"border-green-700\",\r\n      };\r\n    case \"SINGLE_PERSON_PRESENT\":\r\n      return {\r\n        label: \"One person detected\",\r\n        color: \"text-green-300\",\r\n        border: \"border-green-600\",\r\n      };\r\n    case \"MULTIPLE_PEOPLE_PRESENT\":\r\n      return {\r\n        label: \"Multiple people detected\",\r\n        color: \"text-yellow-400\",\r\n        border: \"border-yellow-600\",\r\n      };\r\n    case \"CROWD_ENVIRONMENT\":\r\n      return {\r\n        label: \"Crowded environment\",\r\n        color: \"text-red-400\",\r\n        border: \"border-red-700\",\r\n      };\r\n    default:\r\n      return {\r\n        label: \"Analyzing environment\",\r\n        color: \"text-zinc-400\",\r\n        border: \"border-zinc-700\",\r\n      };\r\n  }\r\n}\r\n\r\nexport default function SceneStatus({ sceneState }: Props) {\r\n  const cfg = getStatusConfig(sceneState);\r\n\r\n  return (\r\n    <div\r\n      className={`rounded-xl border ${cfg.border} bg-zinc-950 p-6`}\r\n    >\r\n      <h2 className=\"text-sm uppercase text-zinc-500\">\r\n        Environment status\r\n      </h2>\r\n\r\n      <p className={`mt-4 text-xl font-semibold ${cfg.color}`}>\r\n        {cfg.label}\r\n      </p>\r\n    </div>\r\n  );\r\n}\r\n"],"names":[],"mappings":";;;;;AAAA;;AAMA,SAAS,gBAAgB,KAAa;IACpC,OAAQ;QACN,KAAK;YACH,OAAO;gBACL,OAAO;gBACP,OAAO;gBACP,QAAQ;YACV;QACF,KAAK;YACH,OAAO;gBACL,OAAO;gBACP,OAAO;gBACP,QAAQ;YACV;QACF,KAAK;YACH,OAAO;gBACL,OAAO;gBACP,OAAO;gBACP,QAAQ;YACV;QACF,KAAK;YACH,OAAO;gBACL,OAAO;gBACP,OAAO;gBACP,QAAQ;YACV;QACF;YACE,OAAO;gBACL,OAAO;gBACP,OAAO;gBACP,QAAQ;YACV;IACJ;AACF;AAEe,SAAS,YAAY,EAAE,UAAU,EAAS;IACvD,MAAM,MAAM,gBAAgB;IAE5B,qBACE,2PAAC;QACC,WAAW,CAAC,kBAAkB,EAAE,IAAI,MAAM,CAAC,gBAAgB,CAAC;;0BAE5D,2PAAC;gBAAG,WAAU;0BAAkC;;;;;;0BAIhD,2PAAC;gBAAE,WAAW,CAAC,2BAA2B,EAAE,IAAI,KAAK,EAAE;0BACpD,IAAI,KAAK;;;;;;;;;;;;AAIlB"}},
    {"offset": {"line": 361, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/luizf/Documents/GitHub/Hallucinationchecker/dashboard/app/components/VoiceAssistant.tsx"],"sourcesContent":["\"use client\";\r\n\r\nimport { useRef, useState } from \"react\";\r\n\r\ntype Props = {\r\n  peopleDetected: number;\r\n  sceneState: string;\r\n};\r\n\r\nconst WAKE_WORD = \"lumi\";\r\n\r\nexport default function VoiceAssistant({\r\n  peopleDetected,\r\n  sceneState,\r\n}: Props) {\r\n  const recognitionRef = useRef<any>(null);\r\n  const audioRef = useRef<HTMLAudioElement | null>(null);\r\n  const busyRef = useRef(false);\r\n  const handledRef = useRef(false); // üîë evita duplica√ß√£o\r\n\r\n  const [status, setStatus] = useState<\r\n    \"idle\" | \"listening\" | \"thinking\" | \"speaking\"\r\n  >(\"idle\");\r\n\r\n  async function sendToVoiceAPI(text: string): Promise<Blob> {\r\n    const res = await fetch(\r\n      \"https://hallucination.calmwave-93bbec10.brazilsouth.azurecontainerapps.io/voice\",\r\n      {\r\n        method: \"POST\",\r\n        headers: {\r\n          \"Content-Type\": \"application/json\",\r\n          Accept: \"audio/mpeg\",\r\n        },\r\n        body: JSON.stringify({\r\n          text,\r\n          people_detected: peopleDetected,\r\n          scene_state: sceneState,\r\n        }),\r\n      }\r\n    );\r\n\r\n    if (!res.ok) {\r\n      throw new Error(`Voice API failed: ${res.status}`);\r\n    }\r\n\r\n    return await res.blob();\r\n  }\r\n\r\n  function startListening() {\r\n    if (busyRef.current) return;\r\n\r\n    const SpeechRecognition =\r\n      (window as any).SpeechRecognition ||\r\n      (window as any).webkitSpeechRecognition;\r\n\r\n    if (!SpeechRecognition) {\r\n      alert(\"Speech Recognition not supported\");\r\n      return;\r\n    }\r\n\r\n    busyRef.current = true;\r\n    handledRef.current = false;\r\n\r\n    const recognition = new SpeechRecognition();\r\n    recognition.lang = \"en-US\";\r\n    recognition.continuous = false; // ‚úÖ MUITO IMPORTANTE\r\n    recognition.interimResults = false;\r\n\r\n    recognition.onresult = async (e: any) => {\r\n      if (handledRef.current) return;\r\n      handledRef.current = true;\r\n\r\n      const transcriptRaw =\r\n        e.results?.[0]?.[0]?.transcript?.trim().toLowerCase();\r\n\r\n      if (!transcriptRaw) {\r\n        reset();\r\n        return;\r\n      }\r\n\r\n      // wake word sozinho ‚Üí ignora\r\n      if (transcriptRaw === WAKE_WORD) {\r\n        reset();\r\n        return;\r\n      }\r\n\r\n      // remove wake word se vier junto\r\n      const transcript = transcriptRaw.startsWith(WAKE_WORD)\r\n        ? transcriptRaw.replace(WAKE_WORD, \"\").trim()\r\n        : transcriptRaw;\r\n\r\n      if (!transcript) {\r\n        reset();\r\n        return;\r\n      }\r\n\r\n      recognition.stop();\r\n      setStatus(\"thinking\");\r\n\r\n      try {\r\n        const audioBlob = await sendToVoiceAPI(transcript);\r\n        playAudio(audioBlob);\r\n      } catch (err) {\r\n        console.error(\"Voice error:\", err);\r\n        reset();\r\n      }\r\n    };\r\n\r\n    recognition.onerror = () => {\r\n      recognition.stop();\r\n      reset();\r\n    };\r\n\r\n    recognitionRef.current = recognition;\r\n    setStatus(\"listening\");\r\n    recognition.start();\r\n  }\r\n\r\n  function playAudio(blob: Blob) {\r\n    setStatus(\"speaking\");\r\n\r\n    if (audioRef.current) {\r\n      audioRef.current.pause();\r\n      audioRef.current.src = \"\";\r\n      audioRef.current = null;\r\n    }\r\n\r\n    const url = URL.createObjectURL(blob);\r\n    const audio = new Audio(url);\r\n    audioRef.current = audio;\r\n\r\n    audio.onended = () => {\r\n      URL.revokeObjectURL(url);\r\n      reset();\r\n    };\r\n\r\n    audio.onerror = () => {\r\n      URL.revokeObjectURL(url);\r\n      reset();\r\n    };\r\n\r\n    audio.play().catch(reset);\r\n  }\r\n\r\n  function reset() {\r\n    busyRef.current = false;\r\n    handledRef.current = false;\r\n    setStatus(\"idle\");\r\n  }\r\n\r\n  return (\r\n    <button\r\n      onClick={startListening}\r\n      disabled={status !== \"idle\"}\r\n      className=\"w-full rounded-xl bg-blue-600 px-4 py-3 font-semibold disabled:opacity-50\"\r\n    >\r\n      {status === \"idle\" && \"üéô Speak\"}\r\n      {status === \"listening\" && \"üëÇ Listening...\"}\r\n      {status === \"thinking\" && \"üß† Thinking...\"}\r\n      {status === \"speaking\" && \"üîä Speaking...\"}\r\n    </button>\r\n  );\r\n}\r\n"],"names":[],"mappings":";;;;;AAEA;AAFA;;;AASA,MAAM,YAAY;AAEH,SAAS,eAAe,EACrC,cAAc,EACd,UAAU,EACJ;IACN,MAAM,iBAAiB,IAAA,4NAAM,EAAM;IACnC,MAAM,WAAW,IAAA,4NAAM,EAA0B;IACjD,MAAM,UAAU,IAAA,4NAAM,EAAC;IACvB,MAAM,aAAa,IAAA,4NAAM,EAAC,QAAQ,sBAAsB;IAExD,MAAM,CAAC,QAAQ,UAAU,GAAG,IAAA,8NAAQ,EAElC;IAEF,eAAe,eAAe,IAAY;QACxC,MAAM,MAAM,MAAM,MAChB,mFACA;YACE,QAAQ;YACR,SAAS;gBACP,gBAAgB;gBAChB,QAAQ;YACV;YACA,MAAM,KAAK,SAAS,CAAC;gBACnB;gBACA,iBAAiB;gBACjB,aAAa;YACf;QACF;QAGF,IAAI,CAAC,IAAI,EAAE,EAAE;YACX,MAAM,IAAI,MAAM,CAAC,kBAAkB,EAAE,IAAI,MAAM,EAAE;QACnD;QAEA,OAAO,MAAM,IAAI,IAAI;IACvB;IAEA,SAAS;QACP,IAAI,QAAQ,OAAO,EAAE;QAErB,MAAM,oBACJ,AAAC,OAAe,iBAAiB,IACjC,AAAC,OAAe,uBAAuB;QAEzC,IAAI,CAAC,mBAAmB;YACtB,MAAM;YACN;QACF;QAEA,QAAQ,OAAO,GAAG;QAClB,WAAW,OAAO,GAAG;QAErB,MAAM,cAAc,IAAI;QACxB,YAAY,IAAI,GAAG;QACnB,YAAY,UAAU,GAAG,OAAO,qBAAqB;QACrD,YAAY,cAAc,GAAG;QAE7B,YAAY,QAAQ,GAAG,OAAO;YAC5B,IAAI,WAAW,OAAO,EAAE;YACxB,WAAW,OAAO,GAAG;YAErB,MAAM,gBACJ,EAAE,OAAO,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,EAAE,YAAY,OAAO;YAE1C,IAAI,CAAC,eAAe;gBAClB;gBACA;YACF;YAEA,6BAA6B;YAC7B,IAAI,kBAAkB,WAAW;gBAC/B;gBACA;YACF;YAEA,iCAAiC;YACjC,MAAM,aAAa,cAAc,UAAU,CAAC,aACxC,cAAc,OAAO,CAAC,WAAW,IAAI,IAAI,KACzC;YAEJ,IAAI,CAAC,YAAY;gBACf;gBACA;YACF;YAEA,YAAY,IAAI;YAChB,UAAU;YAEV,IAAI;gBACF,MAAM,YAAY,MAAM,eAAe;gBACvC,UAAU;YACZ,EAAE,OAAO,KAAK;gBACZ,QAAQ,KAAK,CAAC,gBAAgB;gBAC9B;YACF;QACF;QAEA,YAAY,OAAO,GAAG;YACpB,YAAY,IAAI;YAChB;QACF;QAEA,eAAe,OAAO,GAAG;QACzB,UAAU;QACV,YAAY,KAAK;IACnB;IAEA,SAAS,UAAU,IAAU;QAC3B,UAAU;QAEV,IAAI,SAAS,OAAO,EAAE;YACpB,SAAS,OAAO,CAAC,KAAK;YACtB,SAAS,OAAO,CAAC,GAAG,GAAG;YACvB,SAAS,OAAO,GAAG;QACrB;QAEA,MAAM,MAAM,IAAI,eAAe,CAAC;QAChC,MAAM,QAAQ,IAAI,MAAM;QACxB,SAAS,OAAO,GAAG;QAEnB,MAAM,OAAO,GAAG;YACd,IAAI,eAAe,CAAC;YACpB;QACF;QAEA,MAAM,OAAO,GAAG;YACd,IAAI,eAAe,CAAC;YACpB;QACF;QAEA,MAAM,IAAI,GAAG,KAAK,CAAC;IACrB;IAEA,SAAS;QACP,QAAQ,OAAO,GAAG;QAClB,WAAW,OAAO,GAAG;QACrB,UAAU;IACZ;IAEA,qBACE,2PAAC;QACC,SAAS;QACT,UAAU,WAAW;QACrB,WAAU;;YAET,WAAW,UAAU;YACrB,WAAW,eAAe;YAC1B,WAAW,cAAc;YACzB,WAAW,cAAc;;;;;;;AAGhC"}},
    {"offset": {"line": 490, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/luizf/Documents/GitHub/Hallucinationchecker/dashboard/app/page.tsx"],"sourcesContent":["\"use client\";\n\nimport { useEffect, useState } from \"react\";\nimport CameraView from \"./components/CameraView\";\nimport PeopleCounter from \"./components/PeopleCounter\";\nimport SceneStatus from \"./components/SceneStatus\";\nimport VoiceAssistant from \"./components/VoiceAssistant\";\n\nconst BACKEND_URL =\n  \"https://hallucination.calmwave-93bbec10.brazilsouth.azurecontainerapps.io\";\n\nexport default function Home() {\n  const [peopleDetected, setPeopleDetected] = useState<number>(0);\n  const [sceneState, setSceneState] = useState<string>(\"UNKNOWN\");\n\n  // üîÅ Puxa estado real do backend\n  useEffect(() => {\n    const fetchStatus = async () => {\n      try {\n        const res = await fetch(`${BACKEND_URL}/status`);\n        const data = await res.json();\n\n        setPeopleDetected(data.people_detected ?? 0);\n        setSceneState(data.scene_state ?? \"UNKNOWN\");\n      } catch {\n        // fallback silencioso (demo n√£o quebra)\n      }\n    };\n\n    fetchStatus();\n    const interval = setInterval(fetchStatus, 1000);\n    return () => clearInterval(interval);\n  }, []);\n\n  return (\n    <main className=\"min-h-screen bg-black text-white flex flex-col items-center gap-6 p-6\">\n      <h1 className=\"text-2xl font-bold\">\n        Hallucination Checker ‚Äî Interactive Demo\n      </h1>\n\n      {/* üé• C√¢mera real */}\n      <CameraView />\n\n      {/* üìä Estado objetivo */}\n      <div className=\"flex gap-4\">\n        <PeopleCounter demo={peopleDetected} />\n        <SceneStatus sceneState={sceneState} />\n      </div>\n\n      {/* üéôÔ∏è Voz + IA */}\n      <VoiceAssistant\n        peopleDetected={peopleDetected}\n        sceneState={sceneState}\n      />\n    </main>\n  );\n}\n"],"names":[],"mappings":";;;;;AAEA;AACA;AACA;AACA;AACA;AANA;;;;;;;AAQA,MAAM,cACJ;AAEa,SAAS;IACtB,MAAM,CAAC,gBAAgB,kBAAkB,GAAG,IAAA,8NAAQ,EAAS;IAC7D,MAAM,CAAC,YAAY,cAAc,GAAG,IAAA,8NAAQ,EAAS;IAErD,iCAAiC;IACjC,IAAA,+NAAS,EAAC;QACR,MAAM,cAAc;YAClB,IAAI;gBACF,MAAM,MAAM,MAAM,MAAM,GAAG,YAAY,OAAO,CAAC;gBAC/C,MAAM,OAAO,MAAM,IAAI,IAAI;gBAE3B,kBAAkB,KAAK,eAAe,IAAI;gBAC1C,cAAc,KAAK,WAAW,IAAI;YACpC,EAAE,OAAM;YACN,wCAAwC;YAC1C;QACF;QAEA;QACA,MAAM,WAAW,YAAY,aAAa;QAC1C,OAAO,IAAM,cAAc;IAC7B,GAAG,EAAE;IAEL,qBACE,2PAAC;QAAK,WAAU;;0BACd,2PAAC;gBAAG,WAAU;0BAAqB;;;;;;0BAKnC,2PAAC,wJAAU;;;;;0BAGX,2PAAC;gBAAI,WAAU;;kCACb,2PAAC,2JAAa;wBAAC,MAAM;;;;;;kCACrB,2PAAC,yJAAW;wBAAC,YAAY;;;;;;;;;;;;0BAI3B,2PAAC,4JAAc;gBACb,gBAAgB;gBAChB,YAAY;;;;;;;;;;;;AAIpB"}},
    {"offset": {"line": 585, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/luizf/Documents/GitHub/Hallucinationchecker/dashboard/node_modules/next/src/server/route-modules/app-page/module.compiled.js"],"sourcesContent":["if (process.env.NEXT_RUNTIME === 'edge') {\n  module.exports = require('next/dist/server/route-modules/app-page/module.js')\n} else {\n  if (process.env.__NEXT_EXPERIMENTAL_REACT) {\n    if (process.env.NODE_ENV === 'development') {\n      if (process.env.TURBOPACK) {\n        module.exports = require('next/dist/compiled/next-server/app-page-turbo-experimental.runtime.dev.js')\n      } else {\n        module.exports = require('next/dist/compiled/next-server/app-page-experimental.runtime.dev.js')\n      }\n    } else {\n      if (process.env.TURBOPACK) {\n        module.exports = require('next/dist/compiled/next-server/app-page-turbo-experimental.runtime.prod.js')\n      } else {\n        module.exports = require('next/dist/compiled/next-server/app-page-experimental.runtime.prod.js')\n      }\n    }\n  } else {\n    if (process.env.NODE_ENV === 'development') {\n      if (process.env.TURBOPACK) {\n        module.exports = require('next/dist/compiled/next-server/app-page-turbo.runtime.dev.js')\n      } else {\n        module.exports = require('next/dist/compiled/next-server/app-page.runtime.dev.js')\n      }\n    } else {\n      if (process.env.TURBOPACK) {\n        module.exports = require('next/dist/compiled/next-server/app-page-turbo.runtime.prod.js')\n      } else {\n        module.exports = require('next/dist/compiled/next-server/app-page.runtime.prod.js')\n      }\n    }\n  }\n}\n"],"names":["process","env","NEXT_RUNTIME","module","exports","require","__NEXT_EXPERIMENTAL_REACT","NODE_ENV","TURBOPACK"],"mappings":"AAAA,IAAIA,QAAQC,GAAG,CAACC,YAAY,KAAK,QAAQ;;KAElC;IACL,IAAIF,QAAQC,GAAG,CAACK,yBAAyB,EAAE;;SAcpC;QACL,IAAIN,QAAQC,GAAG,CAACM,QAAQ,KAAK,WAAe;YAC1C,IAAIP,QAAQC,GAAG,CAACO,SAAS,eAAE;gBACzBL,OAAOC,OAAO,GAAGC,QAAQ;YAC3B,OAAO;;QAGT,OAAO;;IAOT;AACF","ignoreList":[0]}},
    {"offset": {"line": 604, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/luizf/Documents/GitHub/Hallucinationchecker/dashboard/node_modules/next/src/server/route-modules/app-page/vendored/ssr/react-jsx-dev-runtime.ts"],"sourcesContent":["module.exports = (\n  require('../../module.compiled') as typeof import('../../module.compiled')\n).vendored['react-ssr']!.ReactJsxDevRuntime\n"],"names":["module","exports","require","vendored","ReactJsxDevRuntime"],"mappings":"AAAAA,OAAOC,OAAO,GACZC,QAAQ,sIACRC,QAAQ,CAAC,YAAY,CAAEC,kBAAkB","ignoreList":[0]}},
    {"offset": {"line": 609, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/luizf/Documents/GitHub/Hallucinationchecker/dashboard/node_modules/next/src/server/route-modules/app-page/vendored/ssr/react.ts"],"sourcesContent":["module.exports = (\n  require('../../module.compiled') as typeof import('../../module.compiled')\n).vendored['react-ssr']!.React\n"],"names":["module","exports","require","vendored","React"],"mappings":"AAAAA,OAAOC,OAAO,GACZC,QAAQ,sIACRC,QAAQ,CAAC,YAAY,CAAEC,KAAK","ignoreList":[0]}}]
}