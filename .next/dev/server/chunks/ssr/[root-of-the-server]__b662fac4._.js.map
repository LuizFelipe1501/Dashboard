{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 10, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/luizf/Documents/GitHub/Hallucinationchecker/dashboard/app/components/CameraView.tsx"],"sourcesContent":["\"use client\";\r\n\r\nimport { useEffect, useRef, useState } from \"react\";\r\n\r\nconst BACKEND_URL =\r\n  \"https://hallucination.calmwave-93bbec10.brazilsouth.azurecontainerapps.io\";\r\n\r\nexport default function CameraView() {\r\n  const videoRef = useRef<HTMLVideoElement>(null);\r\n  const canvasRef = useRef<HTMLCanvasElement>(null);\r\n  const [error, setError] = useState<string | null>(null);\r\n  const sendingRef = useRef(false);\r\n\r\n  // 1ï¸âƒ£ Start camera\r\n  useEffect(() => {\r\n    async function startCamera() {\r\n      try {\r\n        const stream = await navigator.mediaDevices.getUserMedia({\r\n          video: { facingMode: \"user\" },\r\n          audio: false,\r\n        });\r\n\r\n        if (videoRef.current) {\r\n          videoRef.current.srcObject = stream;\r\n        }\r\n      } catch {\r\n        setError(\"Camera access denied or not available.\");\r\n      }\r\n    }\r\n\r\n    startCamera();\r\n\r\n    return () => {\r\n      if (videoRef.current?.srcObject) {\r\n        const tracks = (videoRef.current.srcObject as MediaStream).getTracks();\r\n        tracks.forEach((track) => track.stop());\r\n      }\r\n    };\r\n  }, []);\r\n\r\n  // 2ï¸âƒ£ Capture frame â†’ backend â†’ draw circles\r\n  useEffect(() => {\r\n    const interval = setInterval(captureAndSend, 700); // demo-friendly\r\n    return () => clearInterval(interval);\r\n  }, []);\r\n\r\n  async function captureAndSend() {\r\n    if (sendingRef.current) return;\r\n\r\n    const video = videoRef.current;\r\n    const canvas = canvasRef.current;\r\n    if (!video || !canvas) return;\r\n    if (video.videoWidth === 0) return;\r\n\r\n    sendingRef.current = true;\r\n\r\n    const w = video.videoWidth;\r\n    const h = video.videoHeight;\r\n\r\n    canvas.width = w;\r\n    canvas.height = h;\r\n\r\n    const ctx = canvas.getContext(\"2d\");\r\n    if (!ctx) return;\r\n\r\n    // Draw current frame\r\n    ctx.drawImage(video, 0, 0, w, h);\r\n\r\n    // Convert frame to JPEG\r\n    const blob = await new Promise<Blob | null>((resolve) =>\r\n      canvas.toBlob(resolve, \"image/jpeg\", 0.6)\r\n    );\r\n\r\n    if (!blob) {\r\n      sendingRef.current = false;\r\n      return;\r\n    }\r\n\r\n    const formData = new FormData();\r\n    formData.append(\"file\", blob, \"frame.jpg\");\r\n\r\n    try {\r\n      const res = await fetch(`${BACKEND_URL}/detect`, {\r\n        method: \"POST\",\r\n        body: formData,\r\n      });\r\n\r\n      const data = await res.json();\r\n      drawCircles(data.boxes || []);\r\n    } catch (err) {\r\n      console.warn(\"Detection failed\");\r\n    } finally {\r\n      sendingRef.current = false;\r\n    }\r\n  }\r\n\r\n  function drawCircles(boxes: any[]) {\r\n    const video = videoRef.current;\r\n    const canvas = canvasRef.current;\r\n    if (!video || !canvas) return;\r\n\r\n    const w = video.videoWidth;\r\n    const h = video.videoHeight;\r\n\r\n    const ctx = canvas.getContext(\"2d\");\r\n    if (!ctx) return;\r\n\r\n    ctx.clearRect(0, 0, w, h);\r\n    ctx.strokeStyle = \"lime\";\r\n    ctx.lineWidth = 3;\r\n\r\n    boxes.forEach((b) => {\r\n      const x1 = b.x1 * w;\r\n      const y1 = b.y1 * h;\r\n      const x2 = b.x2 * w;\r\n      const y2 = b.y2 * h;\r\n\r\n      const cx = (x1 + x2) / 2;\r\n      const cy = (y1 + y2) / 2;\r\n      const radius = Math.max(x2 - x1, y2 - y1) / 2;\r\n\r\n      ctx.beginPath();\r\n      ctx.arc(cx, cy, radius, 0, Math.PI * 2);\r\n      ctx.stroke();\r\n    });\r\n  }\r\n\r\n  if (error) {\r\n    return <p className=\"text-red-500\">{error}</p>;\r\n  }\r\n\r\n  return (\r\n    <div className=\"relative w-full max-w-md rounded-xl overflow-hidden shadow-lg\">\r\n      <video\r\n        ref={videoRef}\r\n        autoPlay\r\n        playsInline\r\n        muted\r\n        className=\"w-full h-auto object-contain\"\r\n      />\r\n      <canvas\r\n        ref={canvasRef}\r\n        className=\"absolute top-0 left-0 pointer-events-none\"\r\n      />\r\n    </div>\r\n  );\r\n}\r\n"],"names":[],"mappings":";;;;;AAEA;AAFA;;;AAIA,MAAM,cACJ;AAEa,SAAS;IACtB,MAAM,WAAW,IAAA,4NAAM,EAAmB;IAC1C,MAAM,YAAY,IAAA,4NAAM,EAAoB;IAC5C,MAAM,CAAC,OAAO,SAAS,GAAG,IAAA,8NAAQ,EAAgB;IAClD,MAAM,aAAa,IAAA,4NAAM,EAAC;IAE1B,mBAAmB;IACnB,IAAA,+NAAS,EAAC;QACR,eAAe;YACb,IAAI;gBACF,MAAM,SAAS,MAAM,UAAU,YAAY,CAAC,YAAY,CAAC;oBACvD,OAAO;wBAAE,YAAY;oBAAO;oBAC5B,OAAO;gBACT;gBAEA,IAAI,SAAS,OAAO,EAAE;oBACpB,SAAS,OAAO,CAAC,SAAS,GAAG;gBAC/B;YACF,EAAE,OAAM;gBACN,SAAS;YACX;QACF;QAEA;QAEA,OAAO;YACL,IAAI,SAAS,OAAO,EAAE,WAAW;gBAC/B,MAAM,SAAS,AAAC,SAAS,OAAO,CAAC,SAAS,CAAiB,SAAS;gBACpE,OAAO,OAAO,CAAC,CAAC,QAAU,MAAM,IAAI;YACtC;QACF;IACF,GAAG,EAAE;IAEL,6CAA6C;IAC7C,IAAA,+NAAS,EAAC;QACR,MAAM,WAAW,YAAY,gBAAgB,MAAM,gBAAgB;QACnE,OAAO,IAAM,cAAc;IAC7B,GAAG,EAAE;IAEL,eAAe;QACb,IAAI,WAAW,OAAO,EAAE;QAExB,MAAM,QAAQ,SAAS,OAAO;QAC9B,MAAM,SAAS,UAAU,OAAO;QAChC,IAAI,CAAC,SAAS,CAAC,QAAQ;QACvB,IAAI,MAAM,UAAU,KAAK,GAAG;QAE5B,WAAW,OAAO,GAAG;QAErB,MAAM,IAAI,MAAM,UAAU;QAC1B,MAAM,IAAI,MAAM,WAAW;QAE3B,OAAO,KAAK,GAAG;QACf,OAAO,MAAM,GAAG;QAEhB,MAAM,MAAM,OAAO,UAAU,CAAC;QAC9B,IAAI,CAAC,KAAK;QAEV,qBAAqB;QACrB,IAAI,SAAS,CAAC,OAAO,GAAG,GAAG,GAAG;QAE9B,wBAAwB;QACxB,MAAM,OAAO,MAAM,IAAI,QAAqB,CAAC,UAC3C,OAAO,MAAM,CAAC,SAAS,cAAc;QAGvC,IAAI,CAAC,MAAM;YACT,WAAW,OAAO,GAAG;YACrB;QACF;QAEA,MAAM,WAAW,IAAI;QACrB,SAAS,MAAM,CAAC,QAAQ,MAAM;QAE9B,IAAI;YACF,MAAM,MAAM,MAAM,MAAM,GAAG,YAAY,OAAO,CAAC,EAAE;gBAC/C,QAAQ;gBACR,MAAM;YACR;YAEA,MAAM,OAAO,MAAM,IAAI,IAAI;YAC3B,YAAY,KAAK,KAAK,IAAI,EAAE;QAC9B,EAAE,OAAO,KAAK;YACZ,QAAQ,IAAI,CAAC;QACf,SAAU;YACR,WAAW,OAAO,GAAG;QACvB;IACF;IAEA,SAAS,YAAY,KAAY;QAC/B,MAAM,QAAQ,SAAS,OAAO;QAC9B,MAAM,SAAS,UAAU,OAAO;QAChC,IAAI,CAAC,SAAS,CAAC,QAAQ;QAEvB,MAAM,IAAI,MAAM,UAAU;QAC1B,MAAM,IAAI,MAAM,WAAW;QAE3B,MAAM,MAAM,OAAO,UAAU,CAAC;QAC9B,IAAI,CAAC,KAAK;QAEV,IAAI,SAAS,CAAC,GAAG,GAAG,GAAG;QACvB,IAAI,WAAW,GAAG;QAClB,IAAI,SAAS,GAAG;QAEhB,MAAM,OAAO,CAAC,CAAC;YACb,MAAM,KAAK,EAAE,EAAE,GAAG;YAClB,MAAM,KAAK,EAAE,EAAE,GAAG;YAClB,MAAM,KAAK,EAAE,EAAE,GAAG;YAClB,MAAM,KAAK,EAAE,EAAE,GAAG;YAElB,MAAM,KAAK,CAAC,KAAK,EAAE,IAAI;YACvB,MAAM,KAAK,CAAC,KAAK,EAAE,IAAI;YACvB,MAAM,SAAS,KAAK,GAAG,CAAC,KAAK,IAAI,KAAK,MAAM;YAE5C,IAAI,SAAS;YACb,IAAI,GAAG,CAAC,IAAI,IAAI,QAAQ,GAAG,KAAK,EAAE,GAAG;YACrC,IAAI,MAAM;QACZ;IACF;IAEA,IAAI,OAAO;QACT,qBAAO,2PAAC;YAAE,WAAU;sBAAgB;;;;;;IACtC;IAEA,qBACE,2PAAC;QAAI,WAAU;;0BACb,2PAAC;gBACC,KAAK;gBACL,QAAQ;gBACR,WAAW;gBACX,KAAK;gBACL,WAAU;;;;;;0BAEZ,2PAAC;gBACC,KAAK;gBACL,WAAU;;;;;;;;;;;;AAIlB"}},
    {"offset": {"line": 158, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/luizf/Documents/GitHub/Hallucinationchecker/dashboard/app/components/PeopleCounter.tsx"],"sourcesContent":["\"use client\";\r\nimport { useEffect, useState } from \"react\";\r\n\r\ntype Props = {\r\n  demo?: number | null;\r\n};\r\n\r\nexport default function PeopleCounter({ demo = null }: Props) {\r\n  const [count, setCount] = useState<number>(0);\r\n\r\n  useEffect(() => {\r\n    // DEMO FORÃ‡ADO (ex: banca)\r\n    if (demo !== null) {\r\n      setCount(demo);\r\n      return;\r\n    }\r\n\r\n    let interval: NodeJS.Timeout;\r\n\r\n    const fetchPeople = async () => {\r\n      try {\r\n        const res = await fetch(\r\n          \"https://hallucination.calmwave-93bbec10.brazilsouth.azurecontainerapps.io/status\"\r\n        );\r\n        const data = await res.json();\r\n        setCount(data.people_detected ?? 0);\r\n      } catch {\r\n        // fallback visual inteligente\r\n        setCount(prev => (prev >= 3 ? 1 : prev + 1));\r\n      }\r\n    };\r\n\r\n    fetchPeople();\r\n    interval = setInterval(fetchPeople, 4000);\r\n\r\n    return () => clearInterval(interval);\r\n  }, [demo]);\r\n\r\n  return (\r\n    <div className=\"rounded-xl border border-zinc-800 bg-zinc-950 p-6\">\r\n      <h2 className=\"text-sm text-zinc-400 uppercase\">People Detected</h2>\r\n\r\n      <p className=\"mt-4 text-5xl font-bold text-green-400\">\r\n        {count}\r\n      </p>\r\n\r\n      <p className=\"mt-2 text-xs text-zinc-500\">\r\n        Camera-based detection\r\n      </p>\r\n    </div>\r\n  );\r\n}\r\n"],"names":[],"mappings":";;;;;AACA;AADA;;;AAOe,SAAS,cAAc,EAAE,OAAO,IAAI,EAAS;IAC1D,MAAM,CAAC,OAAO,SAAS,GAAG,IAAA,8NAAQ,EAAS;IAE3C,IAAA,+NAAS,EAAC;QACR,2BAA2B;QAC3B,IAAI,SAAS,MAAM;YACjB,SAAS;YACT;QACF;QAEA,IAAI;QAEJ,MAAM,cAAc;YAClB,IAAI;gBACF,MAAM,MAAM,MAAM,MAChB;gBAEF,MAAM,OAAO,MAAM,IAAI,IAAI;gBAC3B,SAAS,KAAK,eAAe,IAAI;YACnC,EAAE,OAAM;gBACN,8BAA8B;gBAC9B,SAAS,CAAA,OAAS,QAAQ,IAAI,IAAI,OAAO;YAC3C;QACF;QAEA;QACA,WAAW,YAAY,aAAa;QAEpC,OAAO,IAAM,cAAc;IAC7B,GAAG;QAAC;KAAK;IAET,qBACE,2PAAC;QAAI,WAAU;;0BACb,2PAAC;gBAAG,WAAU;0BAAkC;;;;;;0BAEhD,2PAAC;gBAAE,WAAU;0BACV;;;;;;0BAGH,2PAAC;gBAAE,WAAU;0BAA6B;;;;;;;;;;;;AAKhD"}},
    {"offset": {"line": 230, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/luizf/Documents/GitHub/Hallucinationchecker/dashboard/app/components/SceneState.tsx"],"sourcesContent":["\"use client\";\r\nimport { useEffect, useState } from \"react\";\r\n\r\nconst stateMap: Record<string, string> = {\r\n  calm: \"Environment appears calm\",\r\n  crowded: \"Multiple people detected nearby\",\r\n  empty: \"No people detected\",\r\n  unknown: \"Analyzing environmentâ€¦\",\r\n};\r\n\r\nexport default function SceneState() {\r\n  const [state, setState] = useState(\"unknown\");\r\n\r\n  useEffect(() => {\r\n    const fetchState = async () => {\r\n      try {\r\n        const res = await fetch(\r\n          \"https://hallucination.calmwave-93bbec10.brazilsouth.azurecontainerapps.io/status\"\r\n        );\r\n        const data = await res.json();\r\n        setState(data.scene_state ?? \"unknown\");\r\n      } catch {\r\n        setState(\"unknown\");\r\n      }\r\n    };\r\n\r\n    fetchState();\r\n    const interval = setInterval(fetchState, 1500);\r\n    return () => clearInterval(interval);\r\n  }, []);\r\n\r\n  return (\r\n    <div className=\"rounded-xl border border-zinc-800 bg-zinc-950 p-6\">\r\n      <h2 className=\"text-sm text-zinc-400 uppercase\">Scene State</h2>\r\n      <p className=\"mt-4 text-xl font-semibold\">\r\n        {stateMap[state] ?? \"Analyzingâ€¦\"}\r\n      </p>\r\n    </div>\r\n  );\r\n}\r\n"],"names":[],"mappings":";;;;;AACA;AADA;;;AAGA,MAAM,WAAmC;IACvC,MAAM;IACN,SAAS;IACT,OAAO;IACP,SAAS;AACX;AAEe,SAAS;IACtB,MAAM,CAAC,OAAO,SAAS,GAAG,IAAA,8NAAQ,EAAC;IAEnC,IAAA,+NAAS,EAAC;QACR,MAAM,aAAa;YACjB,IAAI;gBACF,MAAM,MAAM,MAAM,MAChB;gBAEF,MAAM,OAAO,MAAM,IAAI,IAAI;gBAC3B,SAAS,KAAK,WAAW,IAAI;YAC/B,EAAE,OAAM;gBACN,SAAS;YACX;QACF;QAEA;QACA,MAAM,WAAW,YAAY,YAAY;QACzC,OAAO,IAAM,cAAc;IAC7B,GAAG,EAAE;IAEL,qBACE,2PAAC;QAAI,WAAU;;0BACb,2PAAC;gBAAG,WAAU;0BAAkC;;;;;;0BAChD,2PAAC;gBAAE,WAAU;0BACV,QAAQ,CAAC,MAAM,IAAI;;;;;;;;;;;;AAI5B"}},
    {"offset": {"line": 291, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/luizf/Documents/GitHub/Hallucinationchecker/dashboard/app/components/VoiceAssistant.tsx"],"sourcesContent":["\"use client\";\r\n\r\nexport default function VoiceAssistant() {\r\n  function speakFast(text: string) {\r\n  const utterance = new SpeechSynthesisUtterance(text);\r\n  utterance.lang = \"pt-BR\"; // ou \"en-US\" para inglÃªs\r\n  utterance.rate = 1.05;\r\n  utterance.pitch = 1;\r\n  window.speechSynthesis.speak(utterance);\r\n}\r\n\r\n\r\n  function startListening() {\r\n    const SpeechRecognition =\r\n      (window as any).SpeechRecognition ||\r\n      (window as any).webkitSpeechRecognition;\r\n\r\n    const recognition = new SpeechRecognition();\r\n    recognition.lang = \"pt-BR\";\r\n    recognition.start();\r\n\r\n    recognition.onresult = async (e: any) => {\r\n      const transcript = e.results[0][0].transcript;\r\n\r\n      const res = await fetch(\r\n        \"https://hallucination.calmwave-93bbec10.brazilsouth.azurecontainerapps.io/voice\",\r\n        {\r\n          method: \"POST\",\r\n          headers: { \"Content-Type\": \"application/json\" },\r\n          body: JSON.stringify({ text: transcript })\r\n        }\r\n      );\r\n\r\n      const data = await res.json();\r\n      if(data.answer) {\r\n        speakFast(data.answer);\r\n      }\r\n    };\r\n  }\r\n\r\n  return (\r\n    <button\r\n      onClick={startListening}\r\n      className=\"w-full p-3 bg-blue-600 rounded mt-4\"\r\n    >\r\n      ðŸŽ™ Ask Lumi\r\n    </button>\r\n  );\r\n}\r\n"],"names":[],"mappings":";;;;;AAAA;;AAEe,SAAS;IACtB,SAAS,UAAU,IAAY;QAC/B,MAAM,YAAY,IAAI,yBAAyB;QAC/C,UAAU,IAAI,GAAG,SAAS,yBAAyB;QACnD,UAAU,IAAI,GAAG;QACjB,UAAU,KAAK,GAAG;QAClB,OAAO,eAAe,CAAC,KAAK,CAAC;IAC/B;IAGE,SAAS;QACP,MAAM,oBACJ,AAAC,OAAe,iBAAiB,IACjC,AAAC,OAAe,uBAAuB;QAEzC,MAAM,cAAc,IAAI;QACxB,YAAY,IAAI,GAAG;QACnB,YAAY,KAAK;QAEjB,YAAY,QAAQ,GAAG,OAAO;YAC5B,MAAM,aAAa,EAAE,OAAO,CAAC,EAAE,CAAC,EAAE,CAAC,UAAU;YAE7C,MAAM,MAAM,MAAM,MAChB,mFACA;gBACE,QAAQ;gBACR,SAAS;oBAAE,gBAAgB;gBAAmB;gBAC9C,MAAM,KAAK,SAAS,CAAC;oBAAE,MAAM;gBAAW;YAC1C;YAGF,MAAM,OAAO,MAAM,IAAI,IAAI;YAC3B,IAAG,KAAK,MAAM,EAAE;gBACd,UAAU,KAAK,MAAM;YACvB;QACF;IACF;IAEA,qBACE,2PAAC;QACC,SAAS;QACT,WAAU;kBACX;;;;;;AAIL"}},
    {"offset": {"line": 342, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/luizf/Documents/GitHub/Hallucinationchecker/dashboard/app/components/WakeWordListener.tsx"],"sourcesContent":["\"use client\";\r\n\r\nimport { useEffect, useRef } from \"react\";\r\n\r\nexport default function WakeWordListener() {\r\n  const mediaRecorderRef = useRef<MediaRecorder | null>(null);\r\n\r\n  useEffect(() => {\r\n    async function startListening() {\r\n      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\r\n\r\n      const mediaRecorder = new MediaRecorder(stream);\r\n      mediaRecorderRef.current = mediaRecorder;\r\n\r\n      mediaRecorder.ondataavailable = async (event) => {\r\n        if (event.data.size === 0) return;\r\n\r\n        const formData = new FormData();\r\n        formData.append(\"audio\", event.data);\r\n\r\n        await fetch(\"http://localhost:8000/wakeword\", {\r\n          method: \"POST\",\r\n          body: formData,\r\n        });\r\n      };\r\n\r\n      mediaRecorder.start(2000); // chunks de 2s\r\n    }\r\n\r\n    startListening();\r\n\r\n    return () => {\r\n      mediaRecorderRef.current?.stop();\r\n    };\r\n  }, []);\r\n\r\n  return null;\r\n}\r\n"],"names":[],"mappings":";;;;AAEA;AAFA;;AAIe,SAAS;IACtB,MAAM,mBAAmB,IAAA,4NAAM,EAAuB;IAEtD,IAAA,+NAAS,EAAC;QACR,eAAe;YACb,MAAM,SAAS,MAAM,UAAU,YAAY,CAAC,YAAY,CAAC;gBAAE,OAAO;YAAK;YAEvE,MAAM,gBAAgB,IAAI,cAAc;YACxC,iBAAiB,OAAO,GAAG;YAE3B,cAAc,eAAe,GAAG,OAAO;gBACrC,IAAI,MAAM,IAAI,CAAC,IAAI,KAAK,GAAG;gBAE3B,MAAM,WAAW,IAAI;gBACrB,SAAS,MAAM,CAAC,SAAS,MAAM,IAAI;gBAEnC,MAAM,MAAM,kCAAkC;oBAC5C,QAAQ;oBACR,MAAM;gBACR;YACF;YAEA,cAAc,KAAK,CAAC,OAAO,eAAe;QAC5C;QAEA;QAEA,OAAO;YACL,iBAAiB,OAAO,EAAE;QAC5B;IACF,GAAG,EAAE;IAEL,OAAO;AACT"}},
    {"offset": {"line": 380, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/luizf/Documents/GitHub/Hallucinationchecker/dashboard/node_modules/next/src/server/route-modules/app-page/module.compiled.js"],"sourcesContent":["if (process.env.NEXT_RUNTIME === 'edge') {\n  module.exports = require('next/dist/server/route-modules/app-page/module.js')\n} else {\n  if (process.env.__NEXT_EXPERIMENTAL_REACT) {\n    if (process.env.NODE_ENV === 'development') {\n      if (process.env.TURBOPACK) {\n        module.exports = require('next/dist/compiled/next-server/app-page-turbo-experimental.runtime.dev.js')\n      } else {\n        module.exports = require('next/dist/compiled/next-server/app-page-experimental.runtime.dev.js')\n      }\n    } else {\n      if (process.env.TURBOPACK) {\n        module.exports = require('next/dist/compiled/next-server/app-page-turbo-experimental.runtime.prod.js')\n      } else {\n        module.exports = require('next/dist/compiled/next-server/app-page-experimental.runtime.prod.js')\n      }\n    }\n  } else {\n    if (process.env.NODE_ENV === 'development') {\n      if (process.env.TURBOPACK) {\n        module.exports = require('next/dist/compiled/next-server/app-page-turbo.runtime.dev.js')\n      } else {\n        module.exports = require('next/dist/compiled/next-server/app-page.runtime.dev.js')\n      }\n    } else {\n      if (process.env.TURBOPACK) {\n        module.exports = require('next/dist/compiled/next-server/app-page-turbo.runtime.prod.js')\n      } else {\n        module.exports = require('next/dist/compiled/next-server/app-page.runtime.prod.js')\n      }\n    }\n  }\n}\n"],"names":["process","env","NEXT_RUNTIME","module","exports","require","__NEXT_EXPERIMENTAL_REACT","NODE_ENV","TURBOPACK"],"mappings":"AAAA,IAAIA,QAAQC,GAAG,CAACC,YAAY,KAAK,QAAQ;;KAElC;IACL,IAAIF,QAAQC,GAAG,CAACK,yBAAyB,EAAE;;SAcpC;QACL,IAAIN,QAAQC,GAAG,CAACM,QAAQ,KAAK,WAAe;YAC1C,IAAIP,QAAQC,GAAG,CAACO,SAAS,eAAE;gBACzBL,OAAOC,OAAO,GAAGC,QAAQ;YAC3B,OAAO;;QAGT,OAAO;;IAOT;AACF","ignoreList":[0]}},
    {"offset": {"line": 399, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/luizf/Documents/GitHub/Hallucinationchecker/dashboard/node_modules/next/src/server/route-modules/app-page/vendored/ssr/react-jsx-dev-runtime.ts"],"sourcesContent":["module.exports = (\n  require('../../module.compiled') as typeof import('../../module.compiled')\n).vendored['react-ssr']!.ReactJsxDevRuntime\n"],"names":["module","exports","require","vendored","ReactJsxDevRuntime"],"mappings":"AAAAA,OAAOC,OAAO,GACZC,QAAQ,sIACRC,QAAQ,CAAC,YAAY,CAAEC,kBAAkB","ignoreList":[0]}},
    {"offset": {"line": 404, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/luizf/Documents/GitHub/Hallucinationchecker/dashboard/node_modules/next/src/server/route-modules/app-page/vendored/ssr/react.ts"],"sourcesContent":["module.exports = (\n  require('../../module.compiled') as typeof import('../../module.compiled')\n).vendored['react-ssr']!.React\n"],"names":["module","exports","require","vendored","React"],"mappings":"AAAAA,OAAOC,OAAO,GACZC,QAAQ,sIACRC,QAAQ,CAAC,YAAY,CAAEC,KAAK","ignoreList":[0]}}]
}